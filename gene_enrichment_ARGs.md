# Complete gene enrichment analysis of ARGs:

You will need now to calculate the read counts per gene NOT contig (that you did to calculate the TPM for taxonomy).

Step 1: Build indexes for predicted genes
```bash
module load apps/bowtie2/2.5.2/gcc-14.1.0
module load apps/samtools/1.17/gcc-14.1.0

for i in $(cat ../../assembly/samples.txt); do bowtie2-build ${i}.ffn ${i}_db; done 
```
Step 2: Create bam files 
```bash
for i in $(cat ../../assembly/samples.txt); do bowtie2 -x ${i}_db -1 ../../preprocess/fastp_results/${i}_*_R1.trimmed.fastq -2 ../../preprocess/fastp_results/${i}_*_R2.trimmed.fastq | samtools view -bS - > ${i}.bam; done 
```

Step 3: calculate feature counts per gene
Note: use the BAM file from the original assemblies not from prodigal 
```bash
source activate /mnt/scratch2/igfs-anaconda/conda-envs/subread
# featureCounts -v
# featureCounts v2.0.1

for i in $(cat ../../assembly/samples.txt); do featureCounts -F GTF -t CDS -g ID -a ${i}.gff -o ${i}_counts.txt ../../assembly/alignment_data/${i}.bam; done
```
example head output we will use in the next stage:
```bash
head D8C42_counts.txt
# Program:featureCounts v2.0.1; Command:"featureCounts" "-F" "GTF" "-t" "CDS" "-g" "ID" "-a" "D8C42.gff" "-o" "D8C42_counts.txt" "../../assembly/alignment_data/D8C42.bam"
Geneid	Chr	Start	End	Strand	Length	../../assembly/alignment_data/D8C42.bam
1_1	NODE_1_length_322100_cov_41.225214	418	2841	+	2424	691
1_2	NODE_1_length_322100_cov_41.225214	2850	4868	+	2019	545
1_3	NODE_1_length_322100_cov_41.225214	4861	6186	+	1326	338
1_4	NODE_1_length_322100_cov_41.225214	6188	6601	+	414	94
1_5	NODE_1_length_322100_cov_41.225214	6651	7715	-	1065	285
1_6	NODE_1_length_322100_cov_41.225214	8060	9331	-	1272	301
1_7	NODE_1_length_322100_cov_41.225214	9337	10464	-	1128	259
1_8	NODE_1_length_322100_cov_41.225214	10522	11352	-	831	183
```
concatenate all feature_counts:
```bash
awk '
BEGIN { OFS="\t" }            
FNR==1 { next }               
FNR==2 && NR!=2 { next }     
FNR>=3 {
    split(FILENAME,a,"_")    
    print a[1], $0           
}
' *_counts.txt > feature_counts_all.txt
```

Step 1: Parse featureCounts Output
We will use python for the following steps.
Note: make sure it is sample_counts.txt and not the summary file generated by featureCounts
```python

import pandas as pd

gene_counts = pd.read_csv("feature_counts_all.txt", sep='\t', names=['sample', 'Geneid', 'Chr', 'Start', 'End', 'Strand', 'Length', 'mapped_reads'])
gene_counts['full_gene_id'] = gene_counts['Chr'] + '_' + gene_counts['Geneid'].str.split('_').str[-1]
gene_counts = gene_counts[['sample', 'full_gene_id', 'Length', 'mapped_reads']]
gene_counts.columns = ['sample', 'gene_id', 'gene_length', 'mapped_reads']
```

Step 2: Link to AMR Annotations

```python
amr_annotations = pd.read_csv("../amrfinder_results/all_args.txt", sep='\t',
                              names=['sample', 'gene_id', 'ARG', 'DrugClass', 'Subclass'])

merged_data = pd.merge(amr_annotations, gene_counts, on=['gene_id', 'sample'])
```


Step 3: Aggregate by AMR Gene 
```python
# group by amr_gene
amr_sample_grouped = merged_data.groupby(['ARG', 'sample'], as_index=False)[['mapped_reads', 'gene_length']].sum()

```

Step 4: Calculate RPK 
```python
amr_sample_grouped['RPK_gene'] = amr_sample_grouped['mapped_reads'] / (amr_sample_grouped['gene_length']/1000)
```
Step 5: Calculate Scaling Factor 
```python
scaling_factor = amr_sample_grouped.groupby(['sample'], as_index=False)['RPK_gene'].sum()
scaling_factor['scaling_factor'] = scaling_factor['RPK_gene'] / 1000000
scaling_factor.rename(columns={'RPK_gene':'RPK_gene_total'}, inplace=True)
```
Step 6: Calculate TPM 
```python
tpm = pd.merge(amr_sample_grouped, scaling_factor, on='sample')
tpm['tpm'] = tpm['RPK_gene'] / tpm['scaling_factor']

# Save
tpm.to_csv("amr_gene_tpm_within_samples.csv", index=False)

# Verify
tpm.groupby('sample')['tpm'].sum()  # Should be 1,000,000 for each sample
```

